{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5be9b4d",
   "metadata": {},
   "source": [
    "# Entrenamiento Modelo\n",
    "Una ves realizado la limpieza y definición de los datos, se proceden a cargar todos estos datos, al modelo para ser entrenado, en este caso se utiliza un modelo, para los datos que no cuentan con las reglas de lipinski \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c9091d",
   "metadata": {},
   "source": [
    "## Requisitos previos:\n",
    "Asegúrate de tener un entorno de Python con las siguientes bibliotecas instaladas: matplotlib, pandas, seaborn, scikit-learn, imbalanced-learn, optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb6d788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, balanced_accuracy_score, matthews_corrcoef, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import optuna\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724d49f5",
   "metadata": {},
   "source": [
    "Seleccion carpeta o localizacion de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73a598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "\n",
    "os.chdir('/home/aamaya/BACE1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc1a80e",
   "metadata": {},
   "source": [
    "### Paso 1: Cargar los datos de entrenamiento\n",
    "El código carga los datos de entrenamiento previamente procesados desde el archivo 'datosentrenamientoSIN_df.pickle'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced8fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datosentrenamientoSIN_df.pickle', 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc833b8",
   "metadata": {},
   "source": [
    "### Paso 2: Dividir los datos en entrenamiento y validación\n",
    "Divide los datos en conjuntos de entrenamiento y validación. En este caso, se usa una proporción del 80% para entrenamiento y 20% para validación. Los datos se dividen de forma estratificada para mantener el equilibrio entre las clases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6e2dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target, validacion = train_test_split(df, test_size=0.20, shuffle=True, stratify=df['active'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411939e2",
   "metadata": {},
   "source": [
    "### Paso 3: Guardar los datos de entrenamiento y validación en archivos pickle\n",
    "Los conjuntos de datos de entrenamiento y validación se guardan en archivos pickle para su uso posterior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d5b6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_targetSIN.pickle', 'wb') as f:\n",
    "    pickle.dump(df_target, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a019477",
   "metadata": {},
   "source": [
    "### Paso 4: Cargar los datos de entrenamiento y validación desde archivos pickle\n",
    "El código carga los conjuntos de datos de entrenamiento y validación desde los archivos pickle guardados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed56ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_targetSIN.pickle', 'rb') as f:\n",
    "    df_train = pickle.load(f)\n",
    "    \n",
    "with open('validacionSIN.pickle', 'wb') as f:\n",
    "    pickle.dump(validacion, f)\n",
    "\n",
    "with open('validacionSIN.pickle', 'rb') as f:\n",
    "    df_val = pickle.load(f)\n",
    "\n",
    "X_train = df_train.np_bv.tolist()\n",
    "y_train = df_train.active\n",
    "X_val = df_val.np_bv.tolist()\n",
    "y_val = df_val.active"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc797568",
   "metadata": {},
   "source": [
    "### Paso 5: Aplicar SMOTE para el balanceo de clases\n",
    "Se utiliza SMOTE (Técnica de Sobremuestreo de Minorías Sintéticas) para equilibrar las clases en los datos de entrenamiento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5305d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy=0.7, random_state=200)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6b4bb6",
   "metadata": {},
   "source": [
    "### Paso 6: Definir métricas de evaluación\n",
    "Se definen las métricas de evaluación que se utilizarán para evaluar el modelo, como precisión, recuperación, F1-score, área bajo la curva ROC (ROC-AUC) y coeficiente de correlación de Matthews (MCC).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081f9ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir metricas de evaluacion\n",
    "scoring = {\n",
    "    'Accuracy': 'accuracy',\n",
    "    'Precision': 'precision',\n",
    "    'Recall': 'recall',\n",
    "    'F1': 'f1',\n",
    "    'ROC-AUC': 'roc_auc',\n",
    "    'MCC': 'matthews_corrcoef'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ccb758",
   "metadata": {},
   "source": [
    "### Paso 7: Definir la función de optimización de hiperparámetros\n",
    "Se define la función objective que utiliza Optuna para optimizar los hiperparámetros del modelo Random Forest. Optuna busca la combinación de hiperparámetros que maximiza una métrica personalizada que combina las métricas de evaluación.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e532d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 10000, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 30, log=True),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20, log=True),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 8),\n",
    "        'max_features': trial.suggest_categorical('max_features', [0.1, 0.3, 0.5, 0.7, 0.8, 0.9, 'sqrt']),\n",
    "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "        'class_weight': trial.suggest_categorical('class_weight', [None, 'balanced', 'balanced_subsample'])\n",
    "    }\n",
    "    rf = RandomForestClassifier(random_state=200, bootstrap=True, **params)\n",
    "    rf_cv = cross_validate(rf, X_resampled, y_resampled, cv=StratifiedKFold(n_splits=5), scoring=scoring, error_score='raise', n_jobs=-1)\n",
    "    accuracy_mean = rf_cv['test_Accuracy'].mean()\n",
    "    precision_mean = rf_cv['test_Precision'].mean()\n",
    "    recall_mean = rf_cv['test_Recall'].mean()\n",
    "    f1_mean = rf_cv['test_F1'].mean()\n",
    "    roc_auc_mean = rf_cv['test_ROC-AUC'].mean()\n",
    "    mcc_mean = rf_cv['test_MCC'].mean()\n",
    "    return -(accuracy_mean + precision_mean + recall_mean + f1_mean + roc_auc_mean + mcc_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b001b",
   "metadata": {},
   "source": [
    "### Paso 8: Realizar la optimización de hiperparámetros\n",
    "Se realiza la optimización de hiperparámetros utilizando Optuna con un número específico de ensayos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace7c6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1170b2",
   "metadata": {},
   "source": [
    "### Paso 9: Obtener los mejores hiperparámetros y entrenar el modelo\n",
    "Se obtienen los mejores hiperparámetros encontrados por Optuna y se entrena el modelo Random Forest con estos parámetros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af236cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "rf = RandomForestClassifier(random_state=200, **best_params)\n",
    "rf.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e8230f",
   "metadata": {},
   "source": [
    "### Paso 10: Guardar el modelo entrenado en un archivo pickle\n",
    "El modelo entrenado se guarda en un archivo pickle para su uso futuro.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa45d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('modelo_entrenadoSIN.pickle', 'wb') as f:\n",
    "    pickle.dump(rf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2b77ae",
   "metadata": {},
   "source": [
    "### Paso 11: Cargar el modelo entrenado y realizar predicciones en datos de validación\n",
    "Se carga el modelo entrenado desde el archivo pickle y se realizan predicciones en el conjunto de datos de validación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92943183",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('modelo_entrenadoSIN.pickle', 'rb') as f:\n",
    "    loaded_rf_model = pickle.load(f)\n",
    "y_pred_val_loaded = loaded_rf_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa9ec64",
   "metadata": {},
   "source": [
    "### Paso 12: Evaluar el modelo en datos de validación\n",
    "Se calculan métricas de evaluación como precisión, recuperación y se genera un informe de clasificación en el conjunto de datos de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afd9804",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_val_loaded = precision_score(y_val, y_pred_val_loaded)\n",
    "recall_val_loaded = recall_score(y_val, y_pred_val_loaded)\n",
    "print('Metricas de evaluacion en los datos de validacion usando el modelo cargado:')\n",
    "print('Precision:', precision_val_loaded)\n",
    "print('Recall:', recall_val_loaded)\n",
    "print('Reporte de clasificacion en conjunto de datos de validacion:')\n",
    "print(classification_report(y_val, y_pred_val_loaded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b754d91",
   "metadata": {},
   "source": [
    "### Paso 13: Visualizar la matriz de confusión\n",
    "La matriz de confusión se visualiza en un mapa de calor utilizando la biblioteca Seaborn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d932fbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_val_loaded = confusion_matrix(y_val, y_pred_val_loaded)\n",
    "sns.heatmap(cm_val_loaded, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2988aea6",
   "metadata": {},
   "source": [
    "### Paso 14: Guardar la matriz de confusión en un archivo CSV\n",
    "La matriz de confusión se guarda en un archivo CSV llamado 'matriz_validacion.csv' para su análisis posterior.\n",
    "Siguiendo estos pasos, podrás entrenar un modelo de clasificación de moléculas, optimizar sus hiperparámetros y evaluar su rendimiento en un conjunto de datos de validación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37033c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm_loaded = pd.DataFrame(cm_val_loaded, index=['Clase ' + str(i) for i in range(cm_val_loaded.shape[0])],\n",
    "                            columns=['Prediccion ' + str(i) for i in range(cm_val_loaded.shape[1])])\n",
    "df_cm_loaded.to_csv('matriz_validacionSIN.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae421c6",
   "metadata": {},
   "source": [
    "Script elaborado por Nelson Alejandro Amaya Orozco, como trabajo de grado, para el grupo de investigacion RamirezLAB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
