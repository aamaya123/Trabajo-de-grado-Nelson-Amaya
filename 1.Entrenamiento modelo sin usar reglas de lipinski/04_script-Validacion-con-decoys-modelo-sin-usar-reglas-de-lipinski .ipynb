{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5be9b4d",
   "metadata": {},
   "source": [
    "# Validacion con el conjunto de decoys para modelo entrenado sin las reglas de lipinski\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c9091d",
   "metadata": {},
   "source": [
    "## Paso 1. Importación de Librerías\n",
    "El código comienza importando varias bibliotecas que se utilizan para diversas tareas, como manipulación de datos, visualización y aprendizaje automático. Algunas de las bibliotecas clave incluyen: chembl_webresource_client, rdkit, seaborn, matplotlib, pandas, numpy, scikit-learn, BayesianOptimization, y pickle. Asegúrate de tener estas bibliotecas instaladas en tu entorno de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb6d788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chembl_webresource_client.new_client import new_client\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import RDKFingerprint\n",
    "from rdkit.Chem.AllChem import GetMorganFingerprintAsBitVect\n",
    "from rdkit.Chem.AllChem import GetHashedTopologicalTorsionFingerprintAsBitVect\n",
    "from rdkit.Chem import MACCSkeys\n",
    "from rdkit.DataStructs import ConvertToNumpyArray\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit import DataStructs\n",
    "import numpy\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report,precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report,precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn import metrics\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit.Chem import rdMolDescriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724d49f5",
   "metadata": {},
   "source": [
    "Seleccion carpeta o localizacion de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73a598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/aamaya/BACE1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc1a80e",
   "metadata": {},
   "source": [
    "### Paso 1: Carga del Modelo Entrenado\n",
    "El código cambia el directorio de trabajo actual utilizando os.chdir('/home/aamaya/RN').\n",
    "Luego, carga un modelo previamente entrenado desde un archivo pickle llamado 'modelo_entrenado.pickle' para el modelo entrenado con las 5 reglas de lipinski lo almacena en la variable modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced8fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('modelo_entrenadoSIN.pickle', 'rb') as handle:\n",
    "    modelo = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc833b8",
   "metadata": {},
   "source": [
    "### Paso 2:  Carga de los Datos de Validación\n",
    "Los datos de validación, que contienen huellas digitales, se cargan desde un archivo pickle llamado 'decoys_df.pickle' y se almacenan en la variable datos_validacion.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6e2dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('decoys_df.pickle', 'rb') as handle:\n",
    "    datos_validacion = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411939e2",
   "metadata": {},
   "source": [
    "### Paso 3: Conversión de Datos de Validación a DataFrame\n",
    "El código verifica si datos_validacion es un DataFrame de pandas. Si no lo es, intenta convertirlo en uno.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d5b6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(datos_validacion))\n",
    "if not isinstance(datos_validacion, pd.DataFrame):\n",
    "    try:\n",
    "        datos_validacion = pd.DataFrame(datos_validacion)\n",
    "    except Exception as e:\n",
    "        print(\"Error al cargar datos_validacion como DataFrame:\", e)\n",
    "        exit(1)\n",
    "\n",
    "print(datos_validacion.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a019477",
   "metadata": {},
   "source": [
    "### Paso 4:Preparación de Datos de Validación\n",
    "Los datos de validación se procesan para obtener solo las huellas digitales y se convierten en una matriz NumPy X_val.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed56ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprints = datos_validacion.iloc[:, 0].values\n",
    "X_val = np.array([list(fp.ToBitString()) for fp in fingerprints], dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc797568",
   "metadata": {},
   "source": [
    "### Paso 5: Realización de Predicciones\n",
    "Se utilizan el modelo cargado para realizar predicciones en los datos de validación. Las predicciones se almacenan en y_pred, y las probabilidades en y_proba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5305d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = modelo.predict(X_val)\n",
    "y_proba = modelo.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6b4bb6",
   "metadata": {},
   "source": [
    "### Paso 6: Creación de un DataFrame con Resultados\n",
    "Se crea un DataFrame df que contiene las predicciones (y_pred) y las probabilidades de pertenencia a dos clases (y_proba_0 y y_proba_1).\n",
    "Este DataFrame se guarda en un archivo CSV llamado 'datos_probabilidadSIN.csv' y en un archivo pickle 'df_probabilidadSIN.pickle'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081f9ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'y_pred': y_pred, 'y_proba_0': y_proba[:, 0], 'y_proba_1': y_proba[:, 1]})\n",
    "df.to_csv('datos_probabilidadSIN.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ccb758",
   "metadata": {},
   "source": [
    "### Paso 7: Visualización de Resultados\n",
    "Se genera un histograma que muestra la distribución de las probabilidades de pertenencia a una de las dos clases. Se utilizan las probabilidades de la clase positiva (y_proba_1).\n",
    "El histograma se guarda como una imagen llamada 'histogramaSIN.png'. La apariencia del histograma se personaliza mediante ajustes como el rango, el color y la legenda.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e532d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_probabilidadSIN.pickle', 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "range_correct = (0, 1)  # Full range from 0 to 1\n",
    "plt.hist([df[df['y_pred'] == 0]['y_proba_1'], df[df['y_pred'] == 1]['y_proba_1']], bins=20, range=range_correct, alpha=0.5, label=['Inactivo'], color=['red', 'red'], width=0.05)  # Adjust the width as needed (e.g., width=0.1)\n",
    "y_max = max(df['y_proba_1'].max(), df['y_proba_1'].max())\n",
    "plt.ylim(0, y_max + 800)  # Adding a buffer of 40 to the y-axis upper limit\n",
    "plt.legend()\n",
    "total_data_points = len(df)\n",
    "plt.title(f\"C) Histograma de decoys sin aplicar las reglas de Lipinski\\n\" \n",
    "        f\"(n= {total_data_points})\")\n",
    "plt.xlabel(\"Probabilidad de ser activos\")\n",
    "plt.ylabel('Numero de compuestos')\n",
    "plt.savefig('histogramaSIN.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b001b",
   "metadata": {},
   "source": [
    "### Paso 8: Ejecución del Código\n",
    "Asegúrate de que el directorio de trabajo actual tenga acceso a los archivos de modelo y datos de validación. Ejecuta el código, que cargará el modelo, realizará predicciones en los datos de validación y generará un histograma. Los resultados se guardarán en archivos CSV y pickle para su posterior análisis. La imagen del histograma se guardará como 'histogramaSIN.png'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae421c6",
   "metadata": {},
   "source": [
    "Script elaborado por Nelson Alejandro Amaya Orozco, como trabajo de grado, para el grupo de investigacion RamirezLAB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
